{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for nba players stats dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape data (1). Method to collect all players dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_players_df(url):\n",
    "    response = requests.get(url)\n",
    "    cols = ['Player_idx', 'Player', 'From', 'To', 'Position', 'Height', 'Weight', 'Birth Date', 'Colleges', 'Link']\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    table = soup.find('table', attrs={'class':'sortable', 'data-cols-to-freeze':\"1\"}).tbody\n",
    "    df = pd.DataFrame(columns=cols)\n",
    "    trs = table.find_all('tr')\n",
    "\n",
    "    for tr in trs:\n",
    "        tds = tr.find_all('td')\n",
    "        row = [td.text.replace('\\n', '') for td in tds]\n",
    "        th = str(tr.find('th', attrs={'class':'left', 'data-stat': 'player'}).a)\n",
    "        # lenght of  <a href=\"/players/ - 17\n",
    "        link = th[17:th.find('>')-1]\n",
    "        player_id = link[3:-5]\n",
    "        name = th[th.find('>')+1:-4]\n",
    "        link = url[:-2]+link\n",
    "        row.insert(0, player_id)\n",
    "        row.insert(1, name)\n",
    "        row.append(link)\n",
    "        df = df.append(pd.Series(row, index=cols), ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape data (2.1). Method to collect each player career stats. OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_player_stats_df(player_idx, url, table_id):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    table_cols = soup.find('table', attrs={'class':'row_summable', 'id':table_id}).thead\n",
    "    cols = ['Player_idx']\n",
    "    trs = table_cols.find_all('tr')\n",
    "    for tr in trs:\n",
    "        ths = tr.find_all('th')\n",
    "        row = [th.text for th in ths]\n",
    "        cols.extend(row)\n",
    "        \n",
    "    table = soup.find('table', attrs={'class':'row_summable', 'id':table_id}).tbody\n",
    "    df = pd.DataFrame(columns=cols)\n",
    "    trs = table.find_all('tr')\n",
    "\n",
    "    for tr in trs:\n",
    "        tds = tr.find_all('td')\n",
    "        row = [td.text.replace('\\n', '') for td in tds]\n",
    "        try: #player missed all season due injury\n",
    "            th = str(tr.find('th', attrs={'class':'left', 'data-stat': 'season'}).a)\n",
    "            season = th[th.find('>')+1:-4]\n",
    "            row.insert(0, player_idx)\n",
    "            row.insert(1, season)\n",
    "            df = df.append(pd.Series(row, index=cols), ignore_index=True)\n",
    "        except:\n",
    "            pass        \n",
    "    return df.replace(r'^\\s*$', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape data (2.2). Method to collect each player career stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_index(df, index):\n",
    "    df.insert(loc=0, column='Player_idx', value=index)\n",
    "    df.set_index('Player_idx')\n",
    "    return df.replace(r'^\\s*$', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_player_stats_df(player_idx, url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    # all others tables are in comments\n",
    "    other_tables = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "    \n",
    "    per_36_min = pd.DataFrame()\n",
    "    season_totals = pd.DataFrame()\n",
    "    for each in other_tables:\n",
    "        if 'id=\"totals\"' in each:\n",
    "            try:\n",
    "                season_totals = pd.read_html(each)[0]\n",
    "            except:\n",
    "                continue\n",
    "        elif 'id=\"per_minute\"' in each:\n",
    "            try:\n",
    "                per_36_min = pd.read_html(each)[0]\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    per_36_min = set_index(per_36_min, player_idx)\n",
    "    \n",
    "    season_totals = set_index(season_totals, player_idx)\n",
    "    \n",
    "    per_game_table = soup.find_all('table')[0]\n",
    "    per_game_data = [[cell.text for cell in row.find_all(['th','td'])]\n",
    "                        for row in per_game_table.find_all('tr')]\n",
    "    per_game = pd.DataFrame(per_game_data)\n",
    "    per_game.columns = per_game.iloc[0,:]\n",
    "    per_game.drop(index=0,inplace=True)\n",
    "    per_game = per_game.loc[~per_game['Tm'].str.contains('Did Not Play')]\n",
    "    per_game = set_index(per_game, player_idx)\n",
    "    \n",
    "    return per_game, per_36_min, season_totals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape data (3). Collect all players into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = pd.DataFrame()\n",
    "url = 'https://www.basketball-reference.com/players/'\n",
    "\n",
    "letters = list(string.ascii_lowercase)\n",
    "for letter in letters:\n",
    "    players = players.append(create_players_df(url+str(letter)))\n",
    "    \n",
    "players.set_index('Player_idx')\n",
    "players = players.sort_values(by=['Player_idx'])\n",
    "players.to_csv('all_players.csv',index=False)\n",
    "players = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape data (3.1). Collect all players career stats into csv. OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_stats = pd.DataFrame()\n",
    "df = pd.read_csv('all_players.csv')\n",
    "players_df_for_stats= df.drop(columns=['Player', 'From', 'To', 'Position', 'Height', 'Weight', 'Birth Date', 'Colleges'])\n",
    "\n",
    "for i in range(players_df_for_stats.shape[0]):\n",
    "    players_stats = players_stats.append(create_player_stats_df(players_df_for_stats.iloc[i,0], \n",
    "                                                                players_df_for_stats.iloc[i,1], \n",
    "                                                                'per_game'))\n",
    "\n",
    "players_stats.set_index('Player_idx')\n",
    "players_stats.to_csv('players_stats_per_game.csv',index=False)\n",
    "\n",
    "players_stats = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape data (3.2). Collect all players career stats into csvs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df_for_stats = pd.read_csv('all_players.csv')\n",
    "per_game = pd.DataFrame()\n",
    "per_36_min = pd.DataFrame() \n",
    "season_totals = pd.DataFrame()\n",
    "\n",
    "for i in range(players_df_for_stats.shape[0]):\n",
    "    df, df1, df2 = create_player_stats_df(players_df_for_stats.iloc[i,0], players_df_for_stats.iloc[i,-1])\n",
    "    per_game = per_game.append(df)\n",
    "    per_36_min = per_36_min.append(df1)\n",
    "    season_totals = season_totals.append(df2)\n",
    "\n",
    "per_game = per_game[per_game.Age.notna()]\n",
    "per_game.to_csv('per_game.csv',index=False)\n",
    "per_36_min = per_36_min[per_36_min.Age.notna()]\n",
    "per_36_min.to_csv('per_36_min.csv',index=False)\n",
    "season_totals = season_totals[season_totals.Age.notna()]\n",
    "season_totals.to_csv('season_totals.csv',index=False)\n",
    "lst = [players_df_for_stats, per_game, per_36_min, season_totals]\n",
    "del lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape data (3.3). Collect players born countries except USA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://www.basketball-reference.com/friv/birthplaces.fcgi')\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "countries = pd.DataFrame()\n",
    "table = soup.find_all('div')[22] ## table number\n",
    "\n",
    "countries = pd.DataFrame([cell.text for cell in table.find_all(['p'])])\n",
    "countries.rename(columns={countries.columns[0]: 'Country'}, inplace=True)\n",
    "countries['Count'] = countries['Country'].str[:-1].str.split('(').str[1].astype('int')\n",
    "countries['Country'] = countries['Country'].str.split('(').str[0].str[:-1]\n",
    "\n",
    "df = pd.read_csv('countries_def.csv')\n",
    "countries = countries.merge(df, how='inner', left_on=['Country'], right_on = ['Country'])\n",
    "countries['Country'].replace({'Russian Federation': 'Russia'}, inplace=True)\n",
    "countries.set_index('Country')\n",
    "countries.to_csv('countries.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning (1). Remove all seasons before three point era"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_old_seasons_with_missing_data(df):\n",
    "    df = df.loc[df['Lg'] == 'NBA']\n",
    "    three_point_year = 1979\n",
    "    df = df.loc[df.loc[ : , 'Season'].str[:4].astype(int) >= three_point_year]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_game = pd.read_csv('per_game.csv')\n",
    "per_36_min = pd.read_csv('per_36_min.csv')\n",
    "season_totals = pd.read_csv('season_totals.csv')\n",
    "season_totals = season_totals[season_totals.Age.notna()]\n",
    "per_36_min = per_36_min[per_36_min.Age.notna()]\n",
    "\n",
    "per_game = remove_old_seasons_with_missing_data(per_game)\n",
    "per_36_min = remove_old_seasons_with_missing_data(per_36_min)\n",
    "season_totals = remove_old_seasons_with_missing_data(season_totals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning (2). Remove seasons data when player play for more than one team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dublicated_seasons_and_fill_null_columns(df, size):\n",
    "    #remove seasons data when player play for more than one team, and change TOT to team1/team2/..teamN\n",
    "    df['CountTeamsPerSeason'] = df.groupby(['Player_idx','Season'])['Tm'].transform('count')\n",
    "\n",
    "    grouped_teams = df.groupby(['Player_idx','Season']).apply(lambda x: '/'.join(x.Tm)).to_frame()\n",
    "    grouped_teams = grouped_teams.replace(to_replace = 'TOT/', value = '', regex = True)\n",
    "    df = df.merge(grouped_teams, how='inner', left_on=['Player_idx','Season'], right_on = ['Player_idx','Season'])\n",
    "    df.rename(columns={df.columns[size+1]: \"Teams\"}, inplace = True)\n",
    "    df['Tm'] = np.where(df['Tm'] == 'TOT', df['Teams'], df['Tm'])\n",
    "    df.drop(df[(df['Tm'].str.len() == 3) & (df['CountTeamsPerSeason'] > 1)].index, inplace = True)\n",
    "    df = df.drop(df.columns[size:], axis=1)\n",
    "\n",
    "    #fill all null columns\n",
    "    df.fillna({'GS': 0, 'FG%': 0, '3P%': 0, '2P%': 0, 'eFG%': 0, 'FT%': 0}, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_game = remove_dublicated_seasons_and_fill_null_columns(per_game, 31)\n",
    "per_36_min = remove_dublicated_seasons_and_fill_null_columns(per_36_min, 30)\n",
    "season_totals = remove_dublicated_seasons_and_fill_null_columns(season_totals, 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning (3.1).  Players stats per 36 minutes OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_36_min = pd.read_csv('players_stats_per_game_filtered.csv')\n",
    "df_per_36_min['Rate'] = (df_per_36_min['MP'].astype(float)/36).round(2)\n",
    "\n",
    "df_per_36_min = df_per_36_min.loc[df_per_36_min['Rate'] > 0]\n",
    "df_per_36_min = df_per_36_min.drop(['eFG%'], axis=1)\n",
    "df_per_36_min.iloc[:, 9:30] = df_per_36_min.iloc[:, 9:30].div(df_per_36_min.Rate, axis = 0).round(2)\n",
    "#df_per_36_min.to_csv('players_stats_per_36_minutes.csv',index=False)\n",
    "df_per_36_min = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning (3.2). Only players who have played 500 or more matches remain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_filter_for_data_analysis(df, size):\n",
    "    # try filter all players that play 500 and more games per career\n",
    "    df['TotalGames'] = df.groupby(['Player_idx'])['G'].transform('sum')\n",
    "    df = df.loc[df['TotalGames'] >= 500]\n",
    "    df = df.drop(df.columns[size:], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_game = final_filter_for_data_analysis(per_game, 31)\n",
    "per_36_min = final_filter_for_data_analysis(per_36_min, 30)\n",
    "season_totals = final_filter_for_data_analysis(season_totals, 31)\n",
    "\n",
    "per_game = per_game.sort_values(by=['Player_idx', 'Season'])\n",
    "per_36_min = per_36_min.sort_values(by=['Player_idx', 'Season'])\n",
    "season_totals = season_totals.sort_values(by=['Player_idx', 'Season'])\n",
    "\n",
    "per_game.to_csv('per_game.csv',index=False)\n",
    "per_36_min.to_csv('per_36_min.csv',index=False)\n",
    "season_totals.to_csv('season_totals.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
